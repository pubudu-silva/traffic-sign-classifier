{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Traffic Sign Classification using CNN\n",
    "\n",
    "This notebook presents my approach to detecting traffic signs available in the ['German Traffic Sign Dataset'](http://benchmark.ini.rub.de/). The solution involves following highlevel steps:\n",
    "* Exploring and visualizing the dataset\n",
    "* Per-processing samples of the dataset\n",
    "* Augmenting the training dataset\n",
    "* Building a simple CNN classifier and training it\n",
    "* Measuring it's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "training_file = 'train.p'\n",
    "validation_file= 'valid.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "n_classes = max(y_train) +1\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the dataset: sample distribution across classes via histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d787f9d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCuegNzMrnIPezKxwDnozs8I56M3MCvf/Kv2fKf6galUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d8e65cac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d416fe748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# to have the plots embeded in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "plt.hist(y_train, bins='auto')  # plt.hist passes it's arguments to np.histogram\n",
    "plt.title(\"Training histogram for distribution of classes\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_valid, bins='auto')  # plt.hist passes it's arguments to np.histogram\n",
    "plt.title(\"Validating histogram for distribution of classes\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_test, bins='auto')  # plt.hist passes it's arguments to np.histogram\n",
    "plt.title(\"Test histogram for distribution of classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a random sample from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naWJ2RZqYXZEmZlekidkV6Y9Y2q0mFqHcLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d8e65cb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CLAHE to pre-process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Helper function to substitute Y channel of an YUV image with a modified Y channel\n",
    "def add_Y_to_UV(Y, img):\n",
    "    img[:,:,0] = Y\n",
    "    return img\n",
    "\n",
    "\n",
    "#pre-processing with Contrast Limited Adaptive Histogram Equilization\n",
    "def pre_process(img_array):\n",
    "    clahe = cv2.createCLAHE()\n",
    "    YUV_array = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2YUV) for im in img_array])\n",
    "    eqld_array = np.array([add_Y_to_UV(clahe.apply(im[:,:,0]), im) for im in YUV_array])\n",
    "    pre_processed = np.array([cv2.cvtColor(im, cv2.COLOR_YUV2RGB) for im in eqld_array])\n",
    "    return pre_processed.astype('float32')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing all training, validation and testing datasets\n",
    "\n",
    "X_train_preprocessed = pre_process(X_train)\n",
    "X_valid_preprocessed = pre_process(X_valid)\n",
    "X_test_preprocessed = pre_process(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visuallizing the effect of pre-processing: befor and after comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'after')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmsilva/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/figure.py:2022: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAFvCAYAAABXWj29AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XmQnPd93/nPt4+5LwyuwckBeAA8\nBIIUREKiDkaHI8nyStqyY7McR05cobyWdu2Kq3YVV7Ysb1kbJxtJ3rK2bFMlRcyubFkbS5bKtlZm\naFKUKIY2SIEnAOIa3MBwAMx99fHbP6ZZeUwB6g+Anot4v6pYBIefefp5+nn6N99pdPcnUkoCAAAA\nMCe32DsAAAAALCUMyAAAAEAGAzIAAACQwYAMAAAAZDAgAwAAABkMyAAAAEAGAzKWvIgYiIj3XsX3\nbYuIH0XEWET8T/OxbwCAS4uI342IoYg4u9j7AlypwmLvADCP/mdJj6eU7lrsHQGA60lEbJL0m5Ju\nSCkNRkS/pKOSiiml8mLuG+DgGWS8kd0g6aWr+caI4JdHALh6N0g6n1IabMTGWJOx0BiQsVy8JSJe\njoiLEfEfI6JFkiLiQxGxNyKGI+KHEbGj9vW/lfSPJH0hIsYj4paI6I6I/xQRr0bEsYj4NxGRq+V/\nOSKejIjPR8QFSZ+uff1fRMS+2u1+NyJuWJzDB4ClJyI+FRGHay9lezkiPlp7SdwjktbX1t+vSHqi\n9i3Dta+9tfb9l11jIyJFxCci4qCkgwt9bLi+MSBjufhFSf9Y0o2SbpH0byLibklflvRxSSsl/bGk\nb0dEc0rp3ZK+L+mTKaWOlNIrkv5AUrekrZLeJemfSfrnmdu4V9IRSWskfSYiPiLptyT995JW17b3\np/N9oACwjByW9A7Nra2/I+n/0dzf3H1A0una+vvLkt5Zy/fUvvaUucZ+RHNr823zfSBAFgMylosv\npJROpJQuSPqMpAck/UtJf5xSejqlVEkpPSxpRtLu139zROQl/bykf51SGkspDUj6rKRfysROp5T+\nIKVUTilNaW7w/rcppX2118z975J28iwyAMxJKf2/KaXTKaVqSunPNPdM7z3mtztr7L9NKV2orcnA\ngmFAxnJxIvPnY5LWa+41br9Ze3nFcEQMS9pU+3+vt0pSU+17s9vZcJnbUG37/2dm2xckxeu+BwCu\nWxHxzzIvcxuWdIfm1luHs8a+fl0GFgQvesdysSnz582STmtu4fxMSukzxvcPSSppbkF+ObOdU5lM\net33vLb9r17VHgPAG1jtmd4vSnqPpKdSSpWI2Ku5Iff1Xr++St4ae6nvA+YdzyBjufhERGyMiF7N\nvWbtzzS3MP9qRNwbc9oj4qcjovP135xSqkj6uuZeW9xZW9j/leZeL3c5fyTpX0fE7ZJUe5PfzzX6\nwABgmWrX3AD7qiRFxD/X3DPIl/KqpKrm3gPyGtZYLFkMyFgu/kTS32juTXRHJP1uSmmP5l6H/AVJ\nFyUdkvTLP2Eb/6Okidr3/6C2zS9fLpxS+qakfyfpaxExKulFzb3xBACueymllzX3Xo6nJJ2T9CZJ\nT14mO6m59488WXtJxW7WWCxlkRJ/ewEAAAC8hmeQAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMhb0\nc5DzuVwqFPILeZOS/A9RjEt+dOOlcp5cmEnzjZLu7ebz3mnNFb1cavDHUOYLRSuXy7vXird/qeof\nR6pWG7vNZG6vUrFylVLJylXNayuX935X9o5Cqlxvb/41DrdUKatSqboP43nV1t6eunt66ufa2qzt\nRYNP9/S0V5pWNh+nwyMjVq6j88c+IfKScgVv7RwZHrZysxOTVq6js8PKtbS0WDl3nRsbG7NyuZy3\njuTttV0qNjV5t22uYRVzEUvmI7VnxQorVzCvmXPnzlm5nDkRtDab95957sqlspWrmj/z2tvbrZx7\nTTuT0rmzZzQyPFw3uKADcqGQ1/rV9Qt23LW20Tn3AimaW2zNe4NgmBdcszl0dK70Sow6+9ZYuVmZ\nQ5uVkrpXrLZynV1d5ha9Wy7NzJjbk2YmvKy7zVzJ/IE/4v1APX/aW0RnzGurpdMbhGZy3jU4MuMO\n8FZMYf6yGTkvVzEHA/uXVyN3/OyQd5sLoLunR7/yq79WN7dz5w5re+ZlYf+Sv3//fis3bA6W3/rO\nX1m53e98p5XrWOOtYd/5xjet3NFnnrVyO+/ZbeVuu3mblZudHrdyTzz+PSvX3OqtI84vZ69Zv/lS\nxag/rq3D++VhbNZ77E/lvCH+wz//s1ZuzcpeK/f7/8fnrVxreOPb7Vv7rVxHe6uVcwf46elpK3fv\nvfdaue3bt1u5ZLww4hP/8l9Y27qml1hExPsj4kBEHIqIT13LtgAAV4e1GAAa66oH5IjIS/q/NPeh\n3rdJeiAibmvUjgEA6mMtBoDGu5ZnkO+RdCildCSlNCvpa5I+3JjdAgCYWIsBoMGuZUDeIOlE5r9P\n1r72D0TEgxGxJyL22K/7AwC4rngtnpyYWLCdA4Dl6FoG5Eu93+LH3qqRUnoopbQrpbQrb74JDgBg\nu+K1uM185zgAXK+uZWI9KWlT5r83Sjp9bbsDALhCrMUA0GDXMiD/vaSbI2JLRDRJ+gVJ327MbgEA\nTKzFANBgV/05yCmlckR8UtJ3JeUlfTml9FLD9gwAUBdrMQA03jUVhaSU/lrSX1/J91jNXm4DXXhP\ngCfzw/6rySucSAWzjKDofdC42+A3Pe29sSYmX/VyF73b7ehZZ+W6V3gfhN7c1mzlcmY9l1si0Wo2\nMklSOXnnbqLqFXGMjnkFIBfOn7RykyXvvmlp91qeqkXvPpya8a5Bv0nP/Ussb/+qdvOIe7veG4u9\n1qj5axe80rV4RU+PPvKR/65u7vjRAWt7z+3da+U+9KEPWjkl7/z87RPft3KnjgxYueNr+6zcxz/0\nM1bu6EtHrVzOPN5Tg976cHHEK6VxGxCPHj/uBc3Hc2uvXxRybOislbuhf6uVu/3Ot1q59VtvsnK7\nduy0cr/3u79t5WZGvZ8Vb9nlHce9u7z9e/HFF62c684777Ry7hrjNund/6531800u+2MVgoAAAC4\nTjAgAwAAABkMyAAAAEAGAzIAAACQwYAMAAAAZDAgAwAAABkMyAAAAEAGAzIAAACQwYAMAAAAZFxT\nk95VcVrP7CY98zbNtiC3hWu65LVrVXJeM1+X2RCTz3m3OzU1aeUqJa9xb3ps1srNjI9aue5VK61c\noa3VypmFhdL0jBmURi94bUZjYyNWbnzsgpWbnvTu65YOr4kqmr2H+PjslJWbrnjXdCV5D86c+St6\nsprq5K8dplzOvbgMDd63azE7M2s1WLkNeY22+633WLnVq1ZZuVNHD1m5p57dY+X+4HO/b+Ue/B9+\nzcodHXizlzu8z8oV8t61FrNeE+j999dvJ5OkfftfsXJtvV7DpyS96S6vCa5v7XorVw1vTfypD3it\nj1/84z+wci/8yHss/eyHPmrlbtzcb+W23uDlXn7Ba9J717veZeUGz3gNiG6b4/cf/54XNIyNjVk5\nnkEGAAAAMhiQAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMhiQAQAAgAwGZAAAACCDARkAAADIYEAG\nAAAAMha8SS9nFPwks/ouwpvvk8wWLrOaL5m5atlrKZrJT1u51uZmK+ce7vRsycrNjHotcKPjXvvc\n4OAZK1coFK1c3m0oq3jnQ5KqJa91r2Ke42T+Ltrc2mvlCi1NVm6i5DXkzZS8Br9kNuTJbL5rdEFe\nSmYtk3k+Ku72jJi7ZwthYmpSzz73fN1czryfLpz3WjmPHTth5cpl78JwmxjvufdeKzc87j1eBk97\na9gPHn3Eyv3UBz9g5d52r9cw2GQ2aF4YOm/lWtu8nz13nfLa01b2rbFyktTT62U7u7us3LjZfvp/\n/8c/snJPPPqYldt9124rt75vnZVbtdr7WdGz0svd81Zv/06ePOndbo/X9lqa8X729PX1Wbm25vrN\nxDlnEBXPIAMAAAD/AAMyAAAAkMGADAAAAGQwIAMAAAAZDMgAAABABgMyAAAAkMGADAAAAGQwIAMA\nAAAZDMgAAABAxgI36YXCaKGzW7OqXttS2O1anrzZ4Bfm/k1Pe61tZa88TU1F77Q25b3jyFXM+9k8\n3jQ1aeXK5u1W3I4y98KSVDDvm2a3kafgnbzU7DbkeQ1+U7NeS1HVfIy496CbS26Vnt1y6T7WzTZM\ne+1YXlV6lUpFw8Ne86WjZ9VKK9e3cYOVc+/2vS/UbwOUpFXr11u5X/u1X7VyT//wKSv3/P6XrdwX\n9h+wcrvf+XYrt3nLVit3+84dVm7D5n4rd5O3uSsyODhk5YZGRq3ckUPeff3C3ues3F133Grl3nLX\nW6xcc5P3M2Dg6HErd9NNN1k5t6luctL7+a2KFxu56K1D22+9xdtgqv+zO5/3ZiSeQQYAAAAyGJAB\nAACADAZkAAAAIIMBGQAAAMhgQAYAAAAyGJABAACADAZkAAAAIIMBGQAAAMhgQAYAAAAyFrhJz2tI\nsgunzGADu7CujNsIaNZGzZqtaDmzSS8feXN7zd72zPa5glmx4+2dlDfvZ6fF8UpVK96xlKreOZ6e\nnbZyk2aTnt0E1+BrNWe2Frr7V230o9ht8DP3r5GphZDP59XT01U3lzN3eavZ1iW3lTPnrSXumnjs\n2Akr9973vtfKveMd77ByUShauUef+J6Ve/Lxx6zcwX1eg99/ffKHVq6zZ4WVm61465LdxiapWPTu\nww0bN1q5gvm04Nt3v9XK3b3jTVaup6vbyj2/9wUr5zbfPfG9H1i5HXfeYeVWmMcxMTFl5db0rbVy\npbLbnGzk3J9jVgoAAAC4TlzTM8gRMSBpTHOt2+WU0q5G7BQAwMdaDACN1YiXWPyjlNJQA7YDALh6\nrMUA0CC8xAIAAADIuNYBOUn6m4h4JiIevFQgIh6MiD0RsadSNd8YAwC4Ele0Fk9OTCzw7gHA8nKt\nL7G4L6V0OiLWSHokIvanlJ7IBlJKD0l6SJKam5qWztu4AeCN44rW4nUbNrAWA8BPcE3PIKeUTtf+\nPSjpm5LuacROAQB8rMUA0FhXPSBHRHtEdL72Z0k/JenFRu0YAKA+1mIAaLxreYnFWknfjLlCgIKk\nP0kp/X8N2SsAgIu1GAAaLNxmrEZoKhZT36qVdXPJbOGye9EaXKCWM1ue7LauBjdsmYV2yoXZuJdv\nsnIFs8GvWPByBbeZz6zcK1zJhZC8bLnsNUfNlktWbsbcXsls8KuaDX4pedtz14twm/TMU+Ifh9m2\n5F4L5nE4d8vZwSHNzJYaX+d4Fd60Y0f65l/9Vd3ciaMD1vbcFezUyZNWrmCuEU8++aSV23rjzVau\no6OjobnBoQtWrlzxGgEPHz5o5cbGxqzchPlmzSHzONy2sxmzcU/yr4WbzDbHjRs2WLnNG9ZbuXVm\no52rv7/fyrW0tFi5/fv3W7nRi8NWbufOnVau0fs3POztXxiL0e98+n/VwNEjdddiPuYNAAAAyGBA\nBgAAADIYkAEAAIAMBmQAAAAggwEZAAAAyGBABgAAADIYkAEAAIAMBmQAAAAggwEZAAAAyLiWqukr\nF35LXkO5bYF2a1Zj28Tcwr0w+6rMMiMp522vaP4alS8UrVyhzW2rardyLU1mM9+VFOl5xXKanpmx\ncjHpNVuVp7xmq2Se5ErJa6yqVrxroSrvdt3HSGp0o5177bvXgnscRmzhOkvrm56e1sF9XoOVwz22\ndeu9drIzp09buY0bN1q54wPHrNxP/8wHrVx7V7eVu/POO63ciYGjVm7KbBMbNJs2h06dsHKt5s+A\n2Vlv/SrPes2ikhRFryr17Ikj3m1PTVq5ziavQXZ20jvm7t4VVu7gQe++Wbt2rZVbbz7mutq9n8uH\nDx6ycve+dbeVW716tZVzm/mcJr1i0ZtVeAYZAAAAyGBABgAAADIYkAEAAIAMBmQAAAAggwEZAAAA\nyGBABgAAADIYkAEAAIAMBmQAAAAggwEZAAAAyFjYJj2F1S7nllyF2XLllms1ntn+ZfZQua1jKefl\nCi2tVq6ts8vKrTDbpbq7vEahzk6v2afZbFrKXUGXWbXsNVGNT4xbuXTe29502WyYynnby5kNdJWS\n9ygpm417FfdBZ5dcescR0djf+f1GwOVlenpa+/fXb9Jzj6tqLtq3bdtu5cplrwGyYjbGKbwL0n28\nFM3jHTx9ysrt+eEPrdy+l1+2clHw1sTuLm9tL5W8dWmmNGvlJiamrJwkTZW9bRZzZpPram+NaG3x\nmvTca2Z6etrKKXlj2SvDXqNd78oeK9fR2mbljh8/buXc5rsLFy5YuS7zWu3fsrluplj07mOeQQYA\nAAAyGJABAACADAZkAAAAIIMBGQAAAMhgQAYAAAAyGJABAACADAZkAAAAIIMBGQAAAMhgQAYAAAAy\nFrhJz+M26dkWqQ3LPg63JSzn/T5TNBtsOntXWbmVZq7XbNLraPcaewpmG5TbqJi/gk7FiryGrpS8\nhqmquY+5gveQjLx5LTR57VKl2ca2QaWS14SWqt45cRvt3Ma9atU8v1ZKmodVa16latU6l5UGH9bq\nvrVWrmg+DpqavLazinmdudfPcz/aa+XOnjxh5fb816esXLHZu1/y4d0vQ4PnrdypU2esXJvZfnr6\n9GkrJ0l9GzdZuW3bbrdyN23dYuV6u70GutkZb617Zu/zVm7jhvpNcJLU2uo14Z49e9bK9fZ4x7t6\n7RorNzAwYOXe8a53WrmpiUkr56xr7s8dnkEGAAAAMhiQAQAAgAwGZAAAACCDARkAAADIYEAGAAAA\nMhiQAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMha+Sc8oKqpUzNYj8ybdNiy3kc1tW3Ib/BTe7ym5\noteO1NW9wsqtXrXayvWY22s3m30KebM50G0YtFKSzOtKkqanJ6zc2NiwlZuZnbFykXMbxLxcZ5vX\nqjg75R1vbsSKKVW87VWr3mPEjNmPdbuZL+deXcurSa+aktU49a777/e2Zx5+adp7HKxY7bV3njFb\nwm570x1WLsK8HkuzVm7korc+nDnnHUdLi9kcaD71NfSqt39DQ0NWrte8Dm6/c4cXlLTrzW/ztnm7\n16R34w0brVxpatzKPfroY17uO9+1cj2rvaa6t933DivX2dlp5WbLXiNgX1+flSvmvZ9Rvb29Vu7R\nZ561cor6P+enzEZYnkEGAAAAMuoOyBHx5YgYjIgXM1/rjYhHIuJg7d/eU4wAgKvCWgwAC8d5Bvkr\nkt7/uq99StKjKaWbJT1a+28AwPz5iliLAWBB1B2QU0pPSLrwui9/WNLDtT8/LOkjDd4vAEAGazEA\nLJyrfQ3y2pTSGUmq/fuyryqPiAcjYk9E7KlW/TdJAQDquqq1eHLCexMlAFyv5v1Neimlh1JKu1JK\nu3I53hMIAIshuxa3tbcv9u4AwJJ2tRPruYhYJ0m1fw82bpcAACbWYgCYB1c7IH9b0sdqf/6YpG81\nZncAAFeAtRgA5oHzMW9/KukpSdsi4mRE/Iqk35P0vog4KOl9tf8GAMwT1mIAWDh1q05SSg9c5n+9\np8H78t9uU2aTnt205uVybkOeyb1dt0mvqcV73WB3t9dC1d3RbeXaW5utXCFvxRRG0410Bfdf8rbn\nNIe9ZnTUa1Gani5ZuWoyr0Gzfai1rcvKdXV757jS5rUgquq1LVVK3v1SKle87Znn2G65NK+tkHdR\nJ3P/rkUj1+JcLqeOjo66uc527zo7emzAys20e9fZuYOvWrl287XUhw4dsnKTZoPf+KjboDlm5Zpa\nvYa8gROnrFwuX7RylYr3+CuZLWvtnfWvKUm65ZZbrJwkrV690sq1mS2DyVzDBge9VyudO3vSyk2M\ne9dMvuAdxyv7D1q5G7fdaOVWrfQ+Qn3lGq+B98KF13/gzqWdPH7Cyg0cO2Ll+taur5tJZjUr75oD\nAAAAMhiQAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMhiQAQAAgAwGZAAAACCDARkAAADIYEAGAAAA\nMrzargYJJYXqN5jkco1tyHPlct7vC9Wq15qVzP3LF7zT0GK2RnV0dHo5syGvGF7bktuy5radub+9\nlWa9252YmDC3KE1MTHm3XTKvBbNozb0WmootVq7Q5DWXtbZ6t1ua8e7DafP+m5iasXJR8e7AavIa\nktwmPXtzDV6L5l2Sysa1++r5IWtzQ0NebnKyzcodOeq1Zt1zzz1Wbteuu63c83//jJWbGB2xciMj\nXu6lA69Yuch5LWu9vV6DZnV21sr1be63cpv7t1q5TZs2WTlJKle8fRwe9q7BjjZvrbtw0dteqeyt\nYdWy1+Q6cNhrfVy3sd/KJXMRc5tm3Z/fvb29Vs69/3p6eqzc9Mxk3UzV/IHMM8gAAABABgMyAAAA\nkMGADAAAAGQwIAMAAAAZDMgAAABABgMyAAAAkMGADAAAAGQwIAMAAAAZDMgAAABAxoI26SVJyWih\nc5taGt1d5TbkuczDULHonYa2dq89rb3da1vKV70GG5VKViyFXTtmcZq+JGlm2mvSm5wat297ctq7\nb2ZKbnug2ZCX935nLRS8+zrJa6Gqmu2VHR1eQ9dEq9e4lx/1zkmE+bt81btf7BZOu0qvsdf+fOvo\n6NB973h73dzAwIC1vbbODivX2uo1O7oNee72Tp48ZeUmJ+u3cElSueytTefPe016K9dvtnKT4956\nU2jpsnK9a7zc9jtus3Jr1660cuUZ7zgkqd1svtvS792HM2Zj3OlTZ73tzXjXwqqVfVZuZPiYlRs6\n7+1fStusXN6cQ8bGxqzcqrWrrNz5wVet3No+7/5zFItFK8czyAAAAEAGAzIAAACQwYAMAAAAZDAg\nAwAAABkMyAAAAEAGAzIAAACQwYAMAAAAZDAgAwAAABkMyAAAAEDGgjbphaR8zpnJzSY9s6ouJa/p\nJtmtWZ4wm+XaO9qsXEdnu5XLRcXKlWe9RqFceE16EyVve4W8d9lFyTuO0ZEpKzcyYTYHSpqY8o6l\nZDa3tbY2W7n2Du8cNzfnrVyp4jWDpfDaFyO82w3rcS7l3Jz5WPeumCvpvXOb+ZZXk97E5IT+7pk9\nRtJbO4eHh61cX996K7d9+3Yr19LitYsODV2wcoODQ1au1fwZNT7urTn33lu/1VCSzpz1juOn3/cB\nK3fi9Akrt/2O261cwSso07kTR7ygpPe9591Wzm0h/ZvvfsfKHT9+3Mq9+upFK3fH7Xdbuah6Px+b\nzeN1185CwbvdV1/1mu/a272Wy7LZ1Os2ICbjed+q+XObZ5ABAACADAZkAAAAIIMBGQAAAMhgQAYA\nAAAyGJABAACADAZkAAAAIIMBGQAAAMhgQAYAAAAyGJABAACAjAVu0gvlo/5MnsyWomqDG/K8W/Ub\n/HJm61ipZB5veKfLLInR1JjXQFdo8n6PiqYOK+d2jk2Meg1Fwxe9trjJituzJk3Nzlq5srm9gtlI\nNjo2bua8+6YS3u2u6O31ci1eO1LebXnKma2ZbqOd+dh0pap3/3kba9ymrtXU1LReeuklI+kd/7Zt\n26xcf3+/lXMdPXrUyo2Pj1q5rk7v+p4cOm/lmpu8NXvdpnVWrrO7x8o996MnrdzFEe9+6b95k5Xr\naPKaDd98904rJ0krujqtXKe5Nq1ducrK3X6b1+b4oQ/+jJV7++77rNwXvvAFK/fok945np7yfpaN\nj3k/Ryvmkug2EaaSt3+rVnnnzVlmCwVvNuMZZAAAACCj7oAcEV+OiMGIeDHztU9HxKmI2Fv754Pz\nu5sAcH1jLQaAheM8g/wVSe+/xNc/n1LaWfvnrxu7WwCA1/mKWIsBYEHUHZBTSk9IurAA+wIAuAzW\nYgBYONfyGuRPRsTztb/2W9GwPQIAXAnWYgBosKsdkP9Q0o2Sdko6I+mzlwtGxIMRsSci9lQa+Y5w\nAMBVrcXT094n2ADA9eqqBuSU0rmUUiWlVJX0RUn3/ITsQymlXSmlXfkcH5oBAI1ytWtxi/mRWABw\nvbqqiTUish/a+FFJL14uCwCYH6zFADA/6n6KeUT8qaT7Ja2KiJOSflvS/RGxU3OfyTwg6ePzuI8A\ncN1jLQaAhVN3QE4pPXCJL3/pam4sKcl5HbLbpOfGGl1g5Tbz5dzmOxWtXOSarNyI2cY2M+y1KM3O\neE03JbPCb7ZU8nJTM1au6lYH5r32HElSzmzdS15uYnTEypUL3mtD82YHZjR5xzw+4bUorWxrs3IF\ns0nPbchzH8V2a6b5cq9kNvOZN3tNGrkWNzc368Ybb6yb2779Fmt7r+zbb+VyDb6ftmzZYuVeeO4Z\nK9ca3tp04dVBK3f3Tq8x7hd/8Res3KzZ8DkxMmzligVvIdm8pd/KtbR4TXqjF/0PY6l4p0StHV7L\n4Hve94+t3PiUtya2tHhrotsy+KY7brNy33nsMSs3YzbV5YvmvGK+l6yry2x9fOZZK7d+/Xor53CP\ngRcFAwAAABkMyAAAAEAGAzIAAACQwYAMAAAAZDAgAwAAABkMyAAAAEAGAzIAAACQwYAMAAAAZDAg\nAwAAABkMyAAAAECGWVjbOE7TaGp4OXRjuXtXqZbN7XlVkOWKl8uZjcrR3GzlUsk74qpZSV0xt1d2\nq6HzXh1wPvzrKp/z6r/bmrya0U6zdrOt1asjrZoV1yXzV+D2znYrl3Pr3ave/vnb86pBlbwNulWj\nbnW1m1sqWlpbrBpptxq6UjLPT4O5+9fX12flqmblekvLaSs3eOaslTt15Ih3u+3eehNN3gO/qcVb\n584dO27l3MfB1KzZHy1peHjUyv3F/r+wckcOHbRyhSbv5+PmzZut3KbV3jW490fPW7lSxXvMdXR2\nW7mpae/nd0dnp5WbNre3bds2K9fe7v2M6ujoqJtpNmcfnkEGAAAAMhiQAQAAgAwGZAAAACCDARkA\nAADIYEAGAAAAMhiQAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMha+SS8Z7S9uu5YZdJv5ctHY3xdS\n8pr0mgpeI05eXvtQa7HJypXNpqDmLq+9KdfjXU7Doxet3MjYiJULsyGvUDCb+SR1dHitPStX9lq5\nri6vfSif967BJO+amSl7bUZ9Jg4mAAAY4klEQVTW41JStexd0+WK16Tn5ipu853Mc2w35LmNe0bG\n2tLCaG5qUn//1rq540cHrO3dcccdVm7LDf1W7vHHH7dyTmuWJPXfcJOVe/Kxx6zcyMS0lTsy4DXQ\n3XFgv5UbHhmycnv3Pmvlujq8lrX3vvt9Vm583GsiPHnypJWTpMOHD1u5Q4e8NsLx8XErVzbbIVet\nWmXldty+w8pNT3vX1i1mA13vihVWbkt/v5XrW7vWys1Me/fzmRPeteA26Tnno1DwZhWeQQYAAAAy\nGJABAACADAZkAAAAIIMBGQAAAMhgQAYAAAAyGJABAACADAZkAAAAIIMBGQAAAMhgQAYAAAAyFrhJ\nL5TP1W+6Kle9ti6FWbln5pKZy5m5MNu6Zme8trNps6VoZXuXlWtvL1q5XM77PWqy5DX9Faa87TU3\nefvnNum1tLZaOUla0bvSynV1efd1S7PXbhhmk57bBNdkNgZVZqes3PSM1/LkN+mZ/XJuy6W5Ofsx\nHF4zXzLOh7laLYjzFy7oq1/9at3cA//k563tHTMb9145cMDKlWa96+zQ4dNWLl/wHn+r1qy2cip5\na/Z3H/9bK/fvP/dZK3fuzBkrt2n9Bit31507rdyBAwetXEubt8aOjHgtqZKUKl6jXaHgrRHnL1yw\ncmOjo1bu5CmvLfHisLe9tZs2WbneFV6DX6k0Y+VmpswWxOMnrFxnl3ctHD/hbe/pp5+2chs21L/2\nh4eHrW3xDDIAAACQwYAMAAAAZDAgAwAAABkMyAAAAEAGAzIAAACQwYAMAAAAZDAgAwAAABkMyAAA\nAEAGAzIAAACQsaBNehFSLl+/mSpnNqNVzTaxsFuzzJzZiRVm+1dp1mugmxz32s6mOr0mwt72FitX\nKo9ZuclJrx1ptuw1+7itci0t3nH09PRYOUnq7Oy0ck3FZivnNreZl7TcXrZCmA9x83bHR71zPDEx\nYeVKZpOe23KZqu4d6LZwmptbZqqVisbH6zd7/eVf/qW1vVu3bbdyB195xcqNjnpNV6Pj3trkNjuu\nXem1k7W3ey1ht2zbauX+7tm9Vq5zRZ+V23HHLiu3eeM6K9fS5K1zB/d5TYnVqteOJ/lNrvmit9bl\ni972CmYLqev4aa9xr29Lv5XrMa/VctmbB2Zmxq3c2Lj3M2DTZu/aWr3aa68cPHfOyjUSzyADAAAA\nGXUH5IjYFBGPRcS+iHgpIn699vXeiHgkIg7W/r1i/ncXAK5PrMUAsHCcZ5DLkn4zpXSrpN2SPhER\nt0n6lKRHU0o3S3q09t8AgPnBWgwAC6TugJxSOpNSerb25zFJ+yRtkPRhSQ/XYg9L+sh87SQAXO9Y\niwFg4VzRa5Ajol/SXZKelrQ2pXRGmlu4Ja25zPc8GBF7ImJPpeK/MB8AcGnXuhZPT3lv+AWA65U9\nIEdEh6Q/l/QbKaX6b3+uSSk9lFLalVLalTc/lQAAcGmNWItbWr1PYQCA65U1sUZEUXML8ldTSt+o\nfflcRKyr/f91kgbnZxcBABJrMQAsFOdTLELSlyTtSyl9LvO/vi3pY7U/f0zStxq/ewAAibUYABaS\n80nY90n6JUkvRMRrn2b+W5J+T9LXI+JXJB2X9HPzs4sAALEWA8CCqTsgp5R+oMv3Sb3nSm4sSXL6\njKpmG5bbmZV327D8GjN3g1aqPDtr5abGzaabUe9liQW5DTtmk97EpJWrmO1pUShauWJ7u5VrMXOS\n1NTUZOVyObeRrdGVbGbbZMk7x+PmNTM64rUoTU1NW7mK2ajlFuS57Zr26mEvCY1eOy5xCw1ci3O5\nnNqb6zdQ3nzjTdb2Nm5ab+VeOXTQypXK3nVRNB+nqeI9DlasWmnlKuabHG++5RYrNzLhPV62bPEa\nC2+82TtvN2xaa+VGzg9Zucq0d7/MlL32WEmaNa+FoSFvH6cmvZ9ThYL7nikvd+fdd1u5u9/8FivX\n1eU1w1ZL3rXlNgfmzKWut9vbvw3rvbWjs6PDu2FDs9kMybvmAAAAgAwGZAAAACCDARkAAADIYEAG\nAAAAMhiQAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMhiQAQAAgAyvOqVRklQ1mrP88iqzTcyt4TJj\nEd7vFe5vH1XzhqenvCa9ixcGrVxl1muWS8lroSqVnZ5EqXrZMrB/qNjkXZ6tLfUbwSSpudlrz5Gk\nfN4/e47kxWzlkte+ODEybOUuDF2wcqNjE1ZuesbbP2c9mMvZD04v1+Dmu1zDmxLnVz6fV3d3d92c\n25BXLnnn8a1vfau3vbK35hw69IqVGzzvXd/r+jZ42zt70sptv/VNVq7Q3GblVq5aY+U2rveOY+sN\nm63cV7/3fSs3Pu41crZ2+K2mr7zineOOzi4rd+NNXs616833WLntd3jXQhS9dsiK2TA4OeG1FnaY\nTXU7duywcufOnrVy7s8A19GBgbqZmdkZa1s8gwwAAABkMCADAAAAGQzIAAAAQAYDMgAAAJDBgAwA\nAABkMCADAAAAGQzIAAAAQAYDMgAAAJDBgAwAAABkLGiTXlJSMlpT3KY6t8XMbWoJs+HNLc2quk1/\nZs1a1W1PGx+xcqnsba9QLHrbM++YXMHbXlPBbNJr8pqHmvN5KydJYZ6TlLz2wGQ2wVVKXuvR6KjX\nkHd+aMjKjYx418zY+JSVm3VbFZP3WHcfc+5j2G3hTGYullmTXlOxqI0bN9bNHTp0yNugeR7vu+8+\nKzdb9pqu9u9/2cpt336Llbt1261WrqPNa+88eeqUlbt7Ra+Vq1a9hsHe7h4rNz09beWOn/SaA6dm\nJq1c7oK3ZktSc5vXure2z2t97Oqp3yApSav71lq57dtus3IrVqywcu5aXDbbQNdt2WrlujtbrdzL\nL3uPuclJr/l31VqvHXLdpvrrlSQdOFx/zXLXdZ5BBgAAADIYkAEAAIAMBmQAAAAggwEZAAAAyGBA\nBgAAADIYkAEAAIAMBmQAAAAggwEZAAAAyGBABgAAADIWtEnP5XdSmfO925pl3qq5uSvZohnz2t3K\nJa+Faso8kGLZa43KmY17zWZDnt2nWPba52anvRY4SQ2/r8tmC+K02T40Muw16Y2MjVm5iSmvUatU\n8pq8/MeIa3Ga6iLcxj3velkqUpLK5frncmBgwNreDf39Vq6rp9PKVatee9qaNV4L1+yU9/jr6fXa\nzk6eOGHlmlvarNz06EUrVyh4q+Lo6KiVG7norSOjE9665DLLTyVJ/Vu3WLmdd73ZylXNpSRf8HZy\ntuS1hrqthW6D7OqVK61cm9n66Lazusfh5mZnvcfmoUNHrNzGjZvrZprMC5BnkAEAAIAMBmQAAAAg\ngwEZAAAAyGBABgAAADIYkAEAAIAMBmQAAAAggwEZAAAAyGBABgAAADIYkAEAAICMJdmk59ZwRXiV\nODkzV3XbsNz9y5n7Z7aEJfN2K0ZDliTJPNyKVxSkQtXbYM5sJ5vMeb+/Vc3jHS94TX+SlKreNmfd\ntqDpSSs3aeZmzWa+GbP5rmy2QSmZNVRuOaQXsx9LdoWfubkI8xqsNLw6cF4lJatJb8PGjdb2Dh8+\nbOVOnT1j5Vb2eI12a9evs3JP/eApK/fII49YuS1bvHa3LV1brdzBgwes3PjYiJWbnfEaPi+a27vx\n5pus3OSkt35F3n9ubqXZGJdvylu5YngtahXzB597KMlci+/YcbuVGxnxzl2n2V7Z1OSNg4/+l/9i\n5db29Vm5QwcOWbmjR49auQf+6QN1M0Wa9AAAAIArV3dAjohNEfFYROyLiJci4tdrX/90RJyKiL21\nfz44/7sLANcn1mIAWDjOc+plSb+ZUno2IjolPRMRr/091OdTSv9h/nYPAFDDWgwAC6TugJxSOiPp\nTO3PYxGxT9KG+d4xAMB/w1oMAAvnil6DHBH9ku6S9HTtS5+MiOcj4ssRccl3VUTEgxGxJyL2VM03\ncQEALu9a1+Lx8fEF2lMAWJ7sATkiOiT9uaTfSCmNSvpDSTdK2qm5ZzU+e6nvSyk9lFLalVLalTM/\nlQAAcGmNWIs7OjoWbH8BYDmyJtaIKGpuQf5qSukbkpRSOpdSqqSUqpK+KOme+dtNAABrMQAsDOdT\nLELSlyTtSyl9LvP17AdQflTSi43fPQCAxFoMAAvJ+RSL+yT9kqQXImJv7Wu/JemBiNipuc/6H5D0\n8XnZQwCAxFoMAAvG+RSLH+jSvVN/faU3FpLC6s5qbGuWWaRnN9qF2QRn14Q1+Hjdm3WbgipVry2u\nYrbPlUve9qamvFamQt5rAHJb0SRJ5htKU8U75krZa74rmfehW9yWqu41Y1773s3a3OI796J22zX9\n41g6DXmNXItTSiqVnWvcexys2+h9mMbBgwet3JjZwnXggLe9tk7vNddjY2NWbnR01Mq5PypWrVpl\n5YoFb62bNhs5m1varNyG9Zus3NlBrynRf+BLXSt6rNyavvXmFr2fA23N3n1TNKv0Cu65m5qwcpOT\n3httC83e7a5a3evlzGv1lQNeO6S3Dslq/nRzbisx75oDAAAAMhiQAQAAgAwGZAAAACCDARkAAADI\nYEAGAAAAMhiQAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMryKlQZJchtM3IY8tw+rsXVdfgeQ9/tH\n1Wxtq9rNgeb94ubM2626rXJuDdys1z6Xs9vT/P40+z60G6HMZj57e+7+mZszNXz/Gn67ppy3f9VK\nI8/b0mnlKxaL6jPb6hxHjg1YuZmZkpWbnDTbO2e97VVL3lpyz+7dVm6ded+dPXvWyg0MDFi5rq4u\nK5fLeT97brut38q1tXmtcu7xNre0WDlJmpjwmuXcNseREa8tsVgsetu7cN7KdXd7585tc3Qb7dzW\nx+mWJiu3fr3XWDhr/vw+ffq0ldv1tvus3NYb+utmmpu8Y+UZZAAAACCDARkAAADIYEAGAAAAMhiQ\nAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMhiQAQAAgAwGZAAAACBjQZv0XG4Hl93VZbaiuW1dfqmX\n2UDX8Nt1NbiZr8E7GOb+5cxWNL95UYrwfnf0rxnzvrZSUs5Mej1wUsVsc2x0o10yj6PRnZlusOEN\nfktEtZo0PV2/ra5q3vHOtiTp6NGjVq69vd3KdXd3W7nJybyVW9HTY+VazCY4N+e2ojW6qe7ChQtW\nbmJy0sodPjJg5cyivyty8eJF87bNsSfv7eTx48etXFubd07uefMuK9fR0WHlCgXveGemvHPsNuS5\njXvlstfA29/fb+UaiWeQAQAAgAwGZAAAACCDARkAAADIYEAGAAAAMhiQAQAAgAwGZAAAACCDARkA\nAADIYEAGAAAAMhiQAQAAgIwl2aTnV+mZDXlmS5h7w357mnm7dsua22jnxVz2cdhNdY1tGIzwcsWi\n16YlSZHzsm4LULXqnpTGNu6512rOPHcV81podAHdorU5uo2K3tauZVcaKlWrVvvdsWPHrO0Nnh+y\ncjt27LByk5PjVm6N2UC3Zs12K9fR2WnlZsw2sa4eb3sXR7xGuxtvusnKjY97919TU5OV27x5s5U7\nfvyklXvppZesnCQdP+a1L95///1Wbvutt1q58+e9Zr6uLq/Rzm2+e+Fl7765a8ddVm7NmjVWbrbk\ntWEeeOWQlcuZdYnuz6iBY0esnKL+zyi3DZBnkAEAAIAMBmQAAAAggwEZAAAAyGBABgAAADIYkAEA\nAIAMBmQAAAAggwEZAAAAyGBABgAAADIYkAEAAICMhW3SS40tunJbvapmk57bVOf3YZnbcxsBG90S\n1tCtyW8ENG/YLlQ0c1W3EVBSzuxGc9uCKhVvL6sV81pdpPsw19BmOX89CDvY2LbJRjcCLhXFYlF9\nffUbtpy2PUlau3atlXvzTq/9a3Ri1Mq5jXEtE17uwsiwldu4caOVK5e9xq5R8zhmy9760NLaYuWG\nhrwGxOExb//ODb1q5exmTEnnz5+3ct/73vesnHvu3va23VZuYGDAyrnX1qFDXlPdywdeNm+3z8o5\n64EkTZe8a7pQ8MbLvo0brNwN/f1WrpF4BhkAAADIqDsgR0RLRPxdRDwXES9FxO/Uvr4lIp6OiIMR\n8WcR4ZW6AwCuGGsxACwc5xnkGUnvTindKWmnpPdHxG5J/07S51NKN0u6KOlX5m83AeC6x1oMAAuk\n7oCc5rz2AqRi7Z8k6d2S/nPt6w9L+si87CEAgLUYABaQ9RrkiMhHxF5Jg5IekXRY0nBKqVyLnJR0\nyVdaR8SDEbEnIva4b5YDAPy4Rq3FI6MjC7PDALBMWQNySqmSUtopaaOkeyTdeqnYZb73oZTSrpTS\nLvcd/wCAH9eotbi7q3s+dxMAlr0rmlhTSsOSHpe0W1JPRLz2OR4bJZ1u7K4BAC6FtRgA5pfzKRar\nI6Kn9udWSe+VtE/SY5J+thb7mKRvzddOAsD1jrUYABaO80nO6yQ9HBF5zQ3UX08p/WVEvCzpaxHx\nu5J+JOlL87ifAHC9Yy0GgAVSd0BOKT0v6cfqj1JKRzT3GriGq5r1VY1ulnO3ZreOma+5do/X5XcU\nLU5NmHveIhp8fhezFq3R16r7GGnorfpydjuk+cZds8HPfSzZ7ZVWyi/wuxaLsRZvuaHfyvWbLVdu\n813evONzZu7xxx+3clvN462WyvVDkmYrXm6xOrvcVrmzZwe9DSbvOHp6erztzYNGN7L19XlNde4x\nr1/rbc9tuXz5wH4r5x6Hy30snTx50sq5S6zTbDgzM2Nti3fNAQAAABkMyAAAAEAGAzIAAACQwYAM\nAAAAZDAgAwAAABkMyAAAAEAGAzIAAACQwYAMAAAAZDAgAwAAABmxkO1iEfGqpGOv+/IqSUMLthPz\nh+NYWjiOpYXjkG5IKa1u5M5cLdbiZYHjWFo4jqVl3tfiBR2QL7kDEXtSSrsWdScagONYWjiOpYXj\nWPreKMfGcSwtHMfSwnH4eIkFAAAAkMGADAAAAGQshQH5ocXegQbhOJYWjmNp4TiWvjfKsXEcSwvH\nsbRwHKZFfw0yAAAAsJQshWeQAQAAgCWDARkAAADIWLQBOSLeHxEHIuJQRHxqsfajESJiICJeiIi9\nEbFnsffHFRFfjojBiHgx87XeiHgkIg7W/r1iMffRcZnj+HREnKqdk70R8cHF3EdHRGyKiMciYl9E\nvBQRv177+rI6Jz/hOJbVOYmIloj4u4h4rnYcv1P7+paIeLp2Pv4sIpoWe1+vxRtlLV6u67DEWryU\nsA4vPYu1Fi/Ka5AjIi/pFUnvk3RS0t9LeiCl9PKC70wDRMSApF0ppWX14dsR8U5J45L+U0rpjtrX\n/r2kCyml36v9sFyRUvpfFnM/67nMcXxa0nhK6T8s5r5diYhYJ2ldSunZiOiU9Iykj0j6ZS2jc/IT\njuOfaBmdk4gISe0ppfGIKEr6gaRfl/SvJH0jpfS1iPgjSc+llP5wMff1ar2R1uLlug5LrMVLCevw\n0rNYa/FiPYN8j6RDKaUjKaVZSV+T9OFF2pfrVkrpCUkXXvflD0t6uPbnhzX3gFrSLnMcy05K6UxK\n6dnan8ck7ZO0QcvsnPyE41hW0pzx2n8Wa/8kSe+W9J9rX1/y56MO1uIlgLV46WAdXnoWay1erAF5\ng6QTmf8+qWV64mqSpL+JiGci4sHF3plrtDaldEaae4BJWrPI+3MtPhkRz9f+2m9J/3XY60VEv6S7\nJD2tZXxOXncc0jI7JxGRj4i9kgYlPSLpsKThlFK5Flnua9cbaS1+I63D0jJ+3F/Csnrcv4Z1eOlY\njLV4sQbkuMTXlvPnzd2XUrpb0gckfaL210xYXH8o6UZJOyWdkfTZxd0dX0R0SPpzSb+RUhpd7P25\nWpc4jmV3TlJKlZTSTkkbNfds662Xii3sXjXUG2ktZh1empbd415iHV5qFmMtXqwB+aSkTZn/3ijp\n9CLtyzVLKZ2u/XtQ0jc1d/KWq3O11y699hqmwUXen6uSUjpXe0BVJX1Ry+Sc1F5f9eeSvppS+kbt\ny8vunFzqOJbrOZGklNKwpMcl7ZbUExGF2v9a1muX3kBr8RtsHZaW4eP+Upbj4551eOlayLV4sQbk\nv5d0c+0diE2SfkHStxdpX65JRLTXXgCviGiX9FOSXvzJ37WkfVvSx2p//pikby3ivly11xaymo9q\nGZyT2hsRviRpX0rpc5n/tazOyeWOY7mdk4hYHRE9tT+3Snqv5l7H95ikn63Flvz5qOMNsRa/Addh\naZk97i9nGT7uWYeXmMVaixetSa/20SK/Lykv6csppc8syo5co4jYqrlnKySpIOlPlsuxRMSfSrpf\n0ipJ5yT9tqS/kPR1SZslHZf0cymlJf2mi8scx/2a+yukJGlA0sdfe/3YUhURb5f0fUkvSKrWvvxb\nmnvd2LI5Jz/hOB7QMjonEbFDc2/8yGvuyYSvp5T+t9pj/muSeiX9SNI/TSnNLN6eXps3wlq8nNdh\nibV4KWEdXnoWay2mahoAAADIoEkPAAAAyGBABgAAADIYkAEAAIAMBmQAAAAggwEZAAAAyGBABgAA\nADIYkAEAAICM/x8atNEwB9YrbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d7895def0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,10), tight_layout={'h_pad':3})\n",
    "\n",
    "#before pre-processing\n",
    "sp = fig.add_subplot(1,2,1)\n",
    "im = X_train[6].squeeze()\n",
    "plt.imshow(im)\n",
    "sp.set_title('before')\n",
    "\n",
    "#after pre-processing\n",
    "sp = fig.add_subplot(1,2,2)\n",
    "im_pp = X_train_preprocessed[6].squeeze()\n",
    "plt.imshow(im_pp)\n",
    "sp.set_title('after')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "Data augmentation is used for two reasons:\n",
    "* Balance the uneven distribution of samples in the training dataset across classes\n",
    "* Add variance to the training dataset, that is not captured from a relatively small dataset like 35K. This helps to genaralize the training set to represent all possible inputs to the network\n",
    "\n",
    "To quantify the uneven distribution of the training set, lets print number of samples found per each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_hist(x,y):\n",
    "    print('sample distribution among classes.....')\n",
    "    for c in range(n_classes):\n",
    "        n_samples_of_c = len(y[y==c])\n",
    "        print('Class ', c, ': ', n_samples_of_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class distribution of training set before augmentation...\n",
      "sample distribution among classes.....\n",
      "Class  0 :  180\n",
      "Class  1 :  1980\n",
      "Class  2 :  2010\n",
      "Class  3 :  1260\n",
      "Class  4 :  1770\n",
      "Class  5 :  1650\n",
      "Class  6 :  360\n",
      "Class  7 :  1290\n",
      "Class  8 :  1260\n",
      "Class  9 :  1320\n",
      "Class  10 :  1800\n",
      "Class  11 :  1170\n",
      "Class  12 :  1890\n",
      "Class  13 :  1920\n",
      "Class  14 :  690\n",
      "Class  15 :  540\n",
      "Class  16 :  360\n",
      "Class  17 :  990\n",
      "Class  18 :  1080\n",
      "Class  19 :  180\n",
      "Class  20 :  300\n",
      "Class  21 :  270\n",
      "Class  22 :  330\n",
      "Class  23 :  450\n",
      "Class  24 :  240\n",
      "Class  25 :  1350\n",
      "Class  26 :  540\n",
      "Class  27 :  210\n",
      "Class  28 :  480\n",
      "Class  29 :  240\n",
      "Class  30 :  390\n",
      "Class  31 :  690\n",
      "Class  32 :  210\n",
      "Class  33 :  599\n",
      "Class  34 :  360\n",
      "Class  35 :  1080\n",
      "Class  36 :  330\n",
      "Class  37 :  180\n",
      "Class  38 :  1860\n",
      "Class  39 :  270\n",
      "Class  40 :  300\n",
      "Class  41 :  210\n",
      "Class  42 :  210\n"
     ]
    }
   ],
   "source": [
    "print('class distribution of training set before augmentation...')\n",
    "print_hist(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using keras to generate batches of tensor image data by real-time data augmentation\n",
    "Here types of augmentations are specified. \n",
    "We chose to do: shifts in both width and height, zooming, rotation and shear opeations and **not** horizontal and vertical flips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                  width_shift_range=0.12,\n",
    "                  height_shift_range=0.1,\n",
    "                  zoom_range=0.12,\n",
    "                  rotation_range=10,\n",
    "                  shear_range=0.1,\n",
    "                  fill_mode='nearest',\n",
    "                  horizontal_flip=False,\n",
    "                  vertical_flip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment training set to approximately equalize the sample distribution among classes\n",
    "We also has to multiply the available ~35K dataset by several times, in order to prevent overfiting.\n",
    "Since the largest class is having above 2K samples, we are going to augment the dataset such that each class will have atleast 5K samples. This will result in a training dataset of ~215K sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting class:  0 | original size =  180   ....\n",
      "Class  0 : augmented up to ==> 360  samples\n",
      "Class  0 : augmented up to ==> 540  samples\n",
      "Class  0 : augmented up to ==> 720  samples\n",
      "Class  0 : augmented up to ==> 900  samples\n",
      "Class  0 : augmented up to ==> 1080  samples\n",
      "Class  0 : augmented up to ==> 1260  samples\n",
      "Class  0 : augmented up to ==> 1440  samples\n",
      "Class  0 : augmented up to ==> 1620  samples\n",
      "Class  0 : augmented up to ==> 1800  samples\n",
      "Class  0 : augmented up to ==> 1980  samples\n",
      "Class  0 : augmented up to ==> 2160  samples\n",
      "Class  0 : augmented up to ==> 2340  samples\n",
      "Class  0 : augmented up to ==> 2520  samples\n",
      "Class  0 : augmented up to ==> 2700  samples\n",
      "Class  0 : augmented up to ==> 2880  samples\n",
      "Class  0 : augmented up to ==> 3060  samples\n",
      "Class  0 : augmented up to ==> 3240  samples\n",
      "Class  0 : augmented up to ==> 3420  samples\n",
      "Class  0 : augmented up to ==> 3600  samples\n",
      "Class  0 : augmented up to ==> 3780  samples\n",
      "Class  0 : augmented up to ==> 3960  samples\n",
      "Class  0 : augmented up to ==> 4140  samples\n",
      "Class  0 : augmented up to ==> 4320  samples\n",
      "Class  0 : augmented up to ==> 4500  samples\n",
      "Class  0 : augmented up to ==> 4680  samples\n",
      "Class  0 : augmented up to ==> 4860  samples\n",
      "Class  0 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  1 | original size =  1980   ....\n",
      "Class  1 : augmented up to ==> 3960  samples\n",
      "Class  1 : augmented up to ==> 5940  samples\n",
      "Augmenting class:  2 | original size =  2010   ....\n",
      "Class  2 : augmented up to ==> 4020  samples\n",
      "Class  2 : augmented up to ==> 6030  samples\n",
      "Augmenting class:  3 | original size =  1260   ....\n",
      "Class  3 : augmented up to ==> 2520  samples\n",
      "Class  3 : augmented up to ==> 3780  samples\n",
      "Class  3 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  4 | original size =  1770   ....\n",
      "Class  4 : augmented up to ==> 3540  samples\n",
      "Class  4 : augmented up to ==> 5310  samples\n",
      "Augmenting class:  5 | original size =  1650   ....\n",
      "Class  5 : augmented up to ==> 3300  samples\n",
      "Class  5 : augmented up to ==> 4950  samples\n",
      "Class  5 : augmented up to ==> 6600  samples\n",
      "Augmenting class:  6 | original size =  360   ....\n",
      "Class  6 : augmented up to ==> 720  samples\n",
      "Class  6 : augmented up to ==> 1080  samples\n",
      "Class  6 : augmented up to ==> 1440  samples\n",
      "Class  6 : augmented up to ==> 1800  samples\n",
      "Class  6 : augmented up to ==> 2160  samples\n",
      "Class  6 : augmented up to ==> 2520  samples\n",
      "Class  6 : augmented up to ==> 2880  samples\n",
      "Class  6 : augmented up to ==> 3240  samples\n",
      "Class  6 : augmented up to ==> 3600  samples\n",
      "Class  6 : augmented up to ==> 3960  samples\n",
      "Class  6 : augmented up to ==> 4320  samples\n",
      "Class  6 : augmented up to ==> 4680  samples\n",
      "Class  6 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  7 | original size =  1290   ....\n",
      "Class  7 : augmented up to ==> 2580  samples\n",
      "Class  7 : augmented up to ==> 3870  samples\n",
      "Class  7 : augmented up to ==> 5160  samples\n",
      "Augmenting class:  8 | original size =  1260   ....\n",
      "Class  8 : augmented up to ==> 2520  samples\n",
      "Class  8 : augmented up to ==> 3780  samples\n",
      "Class  8 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  9 | original size =  1320   ....\n",
      "Class  9 : augmented up to ==> 2640  samples\n",
      "Class  9 : augmented up to ==> 3960  samples\n",
      "Class  9 : augmented up to ==> 5280  samples\n",
      "Augmenting class:  10 | original size =  1800   ....\n",
      "Class  10 : augmented up to ==> 3600  samples\n",
      "Class  10 : augmented up to ==> 5400  samples\n",
      "Augmenting class:  11 | original size =  1170   ....\n",
      "Class  11 : augmented up to ==> 2340  samples\n",
      "Class  11 : augmented up to ==> 3510  samples\n",
      "Class  11 : augmented up to ==> 4680  samples\n",
      "Class  11 : augmented up to ==> 5850  samples\n",
      "Augmenting class:  12 | original size =  1890   ....\n",
      "Class  12 : augmented up to ==> 3780  samples\n",
      "Class  12 : augmented up to ==> 5670  samples\n",
      "Augmenting class:  13 | original size =  1920   ....\n",
      "Class  13 : augmented up to ==> 3840  samples\n",
      "Class  13 : augmented up to ==> 5760  samples\n",
      "Augmenting class:  14 | original size =  690   ....\n",
      "Class  14 : augmented up to ==> 1380  samples\n",
      "Class  14 : augmented up to ==> 2070  samples\n",
      "Class  14 : augmented up to ==> 2760  samples\n",
      "Class  14 : augmented up to ==> 3450  samples\n",
      "Class  14 : augmented up to ==> 4140  samples\n",
      "Class  14 : augmented up to ==> 4830  samples\n",
      "Class  14 : augmented up to ==> 5520  samples\n",
      "Augmenting class:  15 | original size =  540   ....\n",
      "Class  15 : augmented up to ==> 1080  samples\n",
      "Class  15 : augmented up to ==> 1620  samples\n",
      "Class  15 : augmented up to ==> 2160  samples\n",
      "Class  15 : augmented up to ==> 2700  samples\n",
      "Class  15 : augmented up to ==> 3240  samples\n",
      "Class  15 : augmented up to ==> 3780  samples\n",
      "Class  15 : augmented up to ==> 4320  samples\n",
      "Class  15 : augmented up to ==> 4860  samples\n",
      "Class  15 : augmented up to ==> 5400  samples\n",
      "Augmenting class:  16 | original size =  360   ....\n",
      "Class  16 : augmented up to ==> 720  samples\n",
      "Class  16 : augmented up to ==> 1080  samples\n",
      "Class  16 : augmented up to ==> 1440  samples\n",
      "Class  16 : augmented up to ==> 1800  samples\n",
      "Class  16 : augmented up to ==> 2160  samples\n",
      "Class  16 : augmented up to ==> 2520  samples\n",
      "Class  16 : augmented up to ==> 2880  samples\n",
      "Class  16 : augmented up to ==> 3240  samples\n",
      "Class  16 : augmented up to ==> 3600  samples\n",
      "Class  16 : augmented up to ==> 3960  samples\n",
      "Class  16 : augmented up to ==> 4320  samples\n",
      "Class  16 : augmented up to ==> 4680  samples\n",
      "Class  16 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  17 | original size =  990   ....\n",
      "Class  17 : augmented up to ==> 1980  samples\n",
      "Class  17 : augmented up to ==> 2970  samples\n",
      "Class  17 : augmented up to ==> 3960  samples\n",
      "Class  17 : augmented up to ==> 4950  samples\n",
      "Class  17 : augmented up to ==> 5940  samples\n",
      "Augmenting class:  18 | original size =  1080   ....\n",
      "Class  18 : augmented up to ==> 2160  samples\n",
      "Class  18 : augmented up to ==> 3240  samples\n",
      "Class  18 : augmented up to ==> 4320  samples\n",
      "Class  18 : augmented up to ==> 5400  samples\n",
      "Augmenting class:  19 | original size =  180   ....\n",
      "Class  19 : augmented up to ==> 360  samples\n",
      "Class  19 : augmented up to ==> 540  samples\n",
      "Class  19 : augmented up to ==> 720  samples\n",
      "Class  19 : augmented up to ==> 900  samples\n",
      "Class  19 : augmented up to ==> 1080  samples\n",
      "Class  19 : augmented up to ==> 1260  samples\n",
      "Class  19 : augmented up to ==> 1440  samples\n",
      "Class  19 : augmented up to ==> 1620  samples\n",
      "Class  19 : augmented up to ==> 1800  samples\n",
      "Class  19 : augmented up to ==> 1980  samples\n",
      "Class  19 : augmented up to ==> 2160  samples\n",
      "Class  19 : augmented up to ==> 2340  samples\n",
      "Class  19 : augmented up to ==> 2520  samples\n",
      "Class  19 : augmented up to ==> 2700  samples\n",
      "Class  19 : augmented up to ==> 2880  samples\n",
      "Class  19 : augmented up to ==> 3060  samples\n",
      "Class  19 : augmented up to ==> 3240  samples\n",
      "Class  19 : augmented up to ==> 3420  samples\n",
      "Class  19 : augmented up to ==> 3600  samples\n",
      "Class  19 : augmented up to ==> 3780  samples\n",
      "Class  19 : augmented up to ==> 3960  samples\n",
      "Class  19 : augmented up to ==> 4140  samples\n",
      "Class  19 : augmented up to ==> 4320  samples\n",
      "Class  19 : augmented up to ==> 4500  samples\n",
      "Class  19 : augmented up to ==> 4680  samples\n",
      "Class  19 : augmented up to ==> 4860  samples\n",
      "Class  19 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  20 | original size =  300   ....\n",
      "Class  20 : augmented up to ==> 600  samples\n",
      "Class  20 : augmented up to ==> 900  samples\n",
      "Class  20 : augmented up to ==> 1200  samples\n",
      "Class  20 : augmented up to ==> 1500  samples\n",
      "Class  20 : augmented up to ==> 1800  samples\n",
      "Class  20 : augmented up to ==> 2100  samples\n",
      "Class  20 : augmented up to ==> 2400  samples\n",
      "Class  20 : augmented up to ==> 2700  samples\n",
      "Class  20 : augmented up to ==> 3000  samples\n",
      "Class  20 : augmented up to ==> 3300  samples\n",
      "Class  20 : augmented up to ==> 3600  samples\n",
      "Class  20 : augmented up to ==> 3900  samples\n",
      "Class  20 : augmented up to ==> 4200  samples\n",
      "Class  20 : augmented up to ==> 4500  samples\n",
      "Class  20 : augmented up to ==> 4800  samples\n",
      "Class  20 : augmented up to ==> 5100  samples\n",
      "Augmenting class:  21 | original size =  270   ....\n",
      "Class  21 : augmented up to ==> 540  samples\n",
      "Class  21 : augmented up to ==> 810  samples\n",
      "Class  21 : augmented up to ==> 1080  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class  21 : augmented up to ==> 1350  samples\n",
      "Class  21 : augmented up to ==> 1620  samples\n",
      "Class  21 : augmented up to ==> 1890  samples\n",
      "Class  21 : augmented up to ==> 2160  samples\n",
      "Class  21 : augmented up to ==> 2430  samples\n",
      "Class  21 : augmented up to ==> 2700  samples\n",
      "Class  21 : augmented up to ==> 2970  samples\n",
      "Class  21 : augmented up to ==> 3240  samples\n",
      "Class  21 : augmented up to ==> 3510  samples\n",
      "Class  21 : augmented up to ==> 3780  samples\n",
      "Class  21 : augmented up to ==> 4050  samples\n",
      "Class  21 : augmented up to ==> 4320  samples\n",
      "Class  21 : augmented up to ==> 4590  samples\n",
      "Class  21 : augmented up to ==> 4860  samples\n",
      "Class  21 : augmented up to ==> 5130  samples\n",
      "Augmenting class:  22 | original size =  330   ....\n",
      "Class  22 : augmented up to ==> 660  samples\n",
      "Class  22 : augmented up to ==> 990  samples\n",
      "Class  22 : augmented up to ==> 1320  samples\n",
      "Class  22 : augmented up to ==> 1650  samples\n",
      "Class  22 : augmented up to ==> 1980  samples\n",
      "Class  22 : augmented up to ==> 2310  samples\n",
      "Class  22 : augmented up to ==> 2640  samples\n",
      "Class  22 : augmented up to ==> 2970  samples\n",
      "Class  22 : augmented up to ==> 3300  samples\n",
      "Class  22 : augmented up to ==> 3630  samples\n",
      "Class  22 : augmented up to ==> 3960  samples\n",
      "Class  22 : augmented up to ==> 4290  samples\n",
      "Class  22 : augmented up to ==> 4620  samples\n",
      "Class  22 : augmented up to ==> 4950  samples\n",
      "Class  22 : augmented up to ==> 5280  samples\n",
      "Augmenting class:  23 | original size =  450   ....\n",
      "Class  23 : augmented up to ==> 900  samples\n",
      "Class  23 : augmented up to ==> 1350  samples\n",
      "Class  23 : augmented up to ==> 1800  samples\n",
      "Class  23 : augmented up to ==> 2250  samples\n",
      "Class  23 : augmented up to ==> 2700  samples\n",
      "Class  23 : augmented up to ==> 3150  samples\n",
      "Class  23 : augmented up to ==> 3600  samples\n",
      "Class  23 : augmented up to ==> 4050  samples\n",
      "Class  23 : augmented up to ==> 4500  samples\n",
      "Class  23 : augmented up to ==> 4950  samples\n",
      "Class  23 : augmented up to ==> 5400  samples\n",
      "Augmenting class:  24 | original size =  240   ....\n",
      "Class  24 : augmented up to ==> 480  samples\n",
      "Class  24 : augmented up to ==> 720  samples\n",
      "Class  24 : augmented up to ==> 960  samples\n",
      "Class  24 : augmented up to ==> 1200  samples\n",
      "Class  24 : augmented up to ==> 1440  samples\n",
      "Class  24 : augmented up to ==> 1680  samples\n",
      "Class  24 : augmented up to ==> 1920  samples\n",
      "Class  24 : augmented up to ==> 2160  samples\n",
      "Class  24 : augmented up to ==> 2400  samples\n",
      "Class  24 : augmented up to ==> 2640  samples\n",
      "Class  24 : augmented up to ==> 2880  samples\n",
      "Class  24 : augmented up to ==> 3120  samples\n",
      "Class  24 : augmented up to ==> 3360  samples\n",
      "Class  24 : augmented up to ==> 3600  samples\n",
      "Class  24 : augmented up to ==> 3840  samples\n",
      "Class  24 : augmented up to ==> 4080  samples\n",
      "Class  24 : augmented up to ==> 4320  samples\n",
      "Class  24 : augmented up to ==> 4560  samples\n",
      "Class  24 : augmented up to ==> 4800  samples\n",
      "Class  24 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  25 | original size =  1350   ....\n",
      "Class  25 : augmented up to ==> 2700  samples\n",
      "Class  25 : augmented up to ==> 4050  samples\n",
      "Class  25 : augmented up to ==> 5400  samples\n",
      "Augmenting class:  26 | original size =  540   ....\n",
      "Class  26 : augmented up to ==> 1080  samples\n",
      "Class  26 : augmented up to ==> 1620  samples\n",
      "Class  26 : augmented up to ==> 2160  samples\n",
      "Class  26 : augmented up to ==> 2700  samples\n",
      "Class  26 : augmented up to ==> 3240  samples\n",
      "Class  26 : augmented up to ==> 3780  samples\n",
      "Class  26 : augmented up to ==> 4320  samples\n",
      "Class  26 : augmented up to ==> 4860  samples\n",
      "Class  26 : augmented up to ==> 5400  samples\n",
      "Augmenting class:  27 | original size =  210   ....\n",
      "Class  27 : augmented up to ==> 420  samples\n",
      "Class  27 : augmented up to ==> 630  samples\n",
      "Class  27 : augmented up to ==> 840  samples\n",
      "Class  27 : augmented up to ==> 1050  samples\n",
      "Class  27 : augmented up to ==> 1260  samples\n",
      "Class  27 : augmented up to ==> 1470  samples\n",
      "Class  27 : augmented up to ==> 1680  samples\n",
      "Class  27 : augmented up to ==> 1890  samples\n",
      "Class  27 : augmented up to ==> 2100  samples\n",
      "Class  27 : augmented up to ==> 2310  samples\n",
      "Class  27 : augmented up to ==> 2520  samples\n",
      "Class  27 : augmented up to ==> 2730  samples\n",
      "Class  27 : augmented up to ==> 2940  samples\n",
      "Class  27 : augmented up to ==> 3150  samples\n",
      "Class  27 : augmented up to ==> 3360  samples\n",
      "Class  27 : augmented up to ==> 3570  samples\n",
      "Class  27 : augmented up to ==> 3780  samples\n",
      "Class  27 : augmented up to ==> 3990  samples\n",
      "Class  27 : augmented up to ==> 4200  samples\n",
      "Class  27 : augmented up to ==> 4410  samples\n",
      "Class  27 : augmented up to ==> 4620  samples\n",
      "Class  27 : augmented up to ==> 4830  samples\n",
      "Class  27 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  28 | original size =  480   ....\n",
      "Class  28 : augmented up to ==> 960  samples\n",
      "Class  28 : augmented up to ==> 1440  samples\n",
      "Class  28 : augmented up to ==> 1920  samples\n",
      "Class  28 : augmented up to ==> 2400  samples\n",
      "Class  28 : augmented up to ==> 2880  samples\n",
      "Class  28 : augmented up to ==> 3360  samples\n",
      "Class  28 : augmented up to ==> 3840  samples\n",
      "Class  28 : augmented up to ==> 4320  samples\n",
      "Class  28 : augmented up to ==> 4800  samples\n",
      "Class  28 : augmented up to ==> 5280  samples\n",
      "Augmenting class:  29 | original size =  240   ....\n",
      "Class  29 : augmented up to ==> 480  samples\n",
      "Class  29 : augmented up to ==> 720  samples\n",
      "Class  29 : augmented up to ==> 960  samples\n",
      "Class  29 : augmented up to ==> 1200  samples\n",
      "Class  29 : augmented up to ==> 1440  samples\n",
      "Class  29 : augmented up to ==> 1680  samples\n",
      "Class  29 : augmented up to ==> 1920  samples\n",
      "Class  29 : augmented up to ==> 2160  samples\n",
      "Class  29 : augmented up to ==> 2400  samples\n",
      "Class  29 : augmented up to ==> 2640  samples\n",
      "Class  29 : augmented up to ==> 2880  samples\n",
      "Class  29 : augmented up to ==> 3120  samples\n",
      "Class  29 : augmented up to ==> 3360  samples\n",
      "Class  29 : augmented up to ==> 3600  samples\n",
      "Class  29 : augmented up to ==> 3840  samples\n",
      "Class  29 : augmented up to ==> 4080  samples\n",
      "Class  29 : augmented up to ==> 4320  samples\n",
      "Class  29 : augmented up to ==> 4560  samples\n",
      "Class  29 : augmented up to ==> 4800  samples\n",
      "Class  29 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  30 | original size =  390   ....\n",
      "Class  30 : augmented up to ==> 780  samples\n",
      "Class  30 : augmented up to ==> 1170  samples\n",
      "Class  30 : augmented up to ==> 1560  samples\n",
      "Class  30 : augmented up to ==> 1950  samples\n",
      "Class  30 : augmented up to ==> 2340  samples\n",
      "Class  30 : augmented up to ==> 2730  samples\n",
      "Class  30 : augmented up to ==> 3120  samples\n",
      "Class  30 : augmented up to ==> 3510  samples\n",
      "Class  30 : augmented up to ==> 3900  samples\n",
      "Class  30 : augmented up to ==> 4290  samples\n",
      "Class  30 : augmented up to ==> 4680  samples\n",
      "Class  30 : augmented up to ==> 5070  samples\n",
      "Augmenting class:  31 | original size =  690   ....\n",
      "Class  31 : augmented up to ==> 1380  samples\n",
      "Class  31 : augmented up to ==> 2070  samples\n",
      "Class  31 : augmented up to ==> 2760  samples\n",
      "Class  31 : augmented up to ==> 3450  samples\n",
      "Class  31 : augmented up to ==> 4140  samples\n",
      "Class  31 : augmented up to ==> 4830  samples\n",
      "Class  31 : augmented up to ==> 5520  samples\n",
      "Augmenting class:  32 | original size =  210   ....\n",
      "Class  32 : augmented up to ==> 420  samples\n",
      "Class  32 : augmented up to ==> 630  samples\n",
      "Class  32 : augmented up to ==> 840  samples\n",
      "Class  32 : augmented up to ==> 1050  samples\n",
      "Class  32 : augmented up to ==> 1260  samples\n",
      "Class  32 : augmented up to ==> 1470  samples\n",
      "Class  32 : augmented up to ==> 1680  samples\n",
      "Class  32 : augmented up to ==> 1890  samples\n",
      "Class  32 : augmented up to ==> 2100  samples\n",
      "Class  32 : augmented up to ==> 2310  samples\n",
      "Class  32 : augmented up to ==> 2520  samples\n",
      "Class  32 : augmented up to ==> 2730  samples\n",
      "Class  32 : augmented up to ==> 2940  samples\n",
      "Class  32 : augmented up to ==> 3150  samples\n",
      "Class  32 : augmented up to ==> 3360  samples\n",
      "Class  32 : augmented up to ==> 3570  samples\n",
      "Class  32 : augmented up to ==> 3780  samples\n",
      "Class  32 : augmented up to ==> 3990  samples\n",
      "Class  32 : augmented up to ==> 4200  samples\n",
      "Class  32 : augmented up to ==> 4410  samples\n",
      "Class  32 : augmented up to ==> 4620  samples\n",
      "Class  32 : augmented up to ==> 4830  samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class  32 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  33 | original size =  599   ....\n",
      "Class  33 : augmented up to ==> 1198  samples\n",
      "Class  33 : augmented up to ==> 1797  samples\n",
      "Class  33 : augmented up to ==> 2396  samples\n",
      "Class  33 : augmented up to ==> 2995  samples\n",
      "Class  33 : augmented up to ==> 3594  samples\n",
      "Class  33 : augmented up to ==> 4193  samples\n",
      "Class  33 : augmented up to ==> 4792  samples\n",
      "Class  33 : augmented up to ==> 5391  samples\n",
      "Augmenting class:  34 | original size =  360   ....\n",
      "Class  34 : augmented up to ==> 720  samples\n",
      "Class  34 : augmented up to ==> 1080  samples\n",
      "Class  34 : augmented up to ==> 1440  samples\n",
      "Class  34 : augmented up to ==> 1800  samples\n",
      "Class  34 : augmented up to ==> 2160  samples\n",
      "Class  34 : augmented up to ==> 2520  samples\n",
      "Class  34 : augmented up to ==> 2880  samples\n",
      "Class  34 : augmented up to ==> 3240  samples\n",
      "Class  34 : augmented up to ==> 3600  samples\n",
      "Class  34 : augmented up to ==> 3960  samples\n",
      "Class  34 : augmented up to ==> 4320  samples\n",
      "Class  34 : augmented up to ==> 4680  samples\n",
      "Class  34 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  35 | original size =  1080   ....\n",
      "Class  35 : augmented up to ==> 2160  samples\n",
      "Class  35 : augmented up to ==> 3240  samples\n",
      "Class  35 : augmented up to ==> 4320  samples\n",
      "Class  35 : augmented up to ==> 5400  samples\n",
      "Augmenting class:  36 | original size =  330   ....\n",
      "Class  36 : augmented up to ==> 660  samples\n",
      "Class  36 : augmented up to ==> 990  samples\n",
      "Class  36 : augmented up to ==> 1320  samples\n",
      "Class  36 : augmented up to ==> 1650  samples\n",
      "Class  36 : augmented up to ==> 1980  samples\n",
      "Class  36 : augmented up to ==> 2310  samples\n",
      "Class  36 : augmented up to ==> 2640  samples\n",
      "Class  36 : augmented up to ==> 2970  samples\n",
      "Class  36 : augmented up to ==> 3300  samples\n",
      "Class  36 : augmented up to ==> 3630  samples\n",
      "Class  36 : augmented up to ==> 3960  samples\n",
      "Class  36 : augmented up to ==> 4290  samples\n",
      "Class  36 : augmented up to ==> 4620  samples\n",
      "Class  36 : augmented up to ==> 4950  samples\n",
      "Class  36 : augmented up to ==> 5280  samples\n",
      "Augmenting class:  37 | original size =  180   ....\n",
      "Class  37 : augmented up to ==> 360  samples\n",
      "Class  37 : augmented up to ==> 540  samples\n",
      "Class  37 : augmented up to ==> 720  samples\n",
      "Class  37 : augmented up to ==> 900  samples\n",
      "Class  37 : augmented up to ==> 1080  samples\n",
      "Class  37 : augmented up to ==> 1260  samples\n",
      "Class  37 : augmented up to ==> 1440  samples\n",
      "Class  37 : augmented up to ==> 1620  samples\n",
      "Class  37 : augmented up to ==> 1800  samples\n",
      "Class  37 : augmented up to ==> 1980  samples\n",
      "Class  37 : augmented up to ==> 2160  samples\n",
      "Class  37 : augmented up to ==> 2340  samples\n",
      "Class  37 : augmented up to ==> 2520  samples\n",
      "Class  37 : augmented up to ==> 2700  samples\n",
      "Class  37 : augmented up to ==> 2880  samples\n",
      "Class  37 : augmented up to ==> 3060  samples\n",
      "Class  37 : augmented up to ==> 3240  samples\n",
      "Class  37 : augmented up to ==> 3420  samples\n",
      "Class  37 : augmented up to ==> 3600  samples\n",
      "Class  37 : augmented up to ==> 3780  samples\n",
      "Class  37 : augmented up to ==> 3960  samples\n",
      "Class  37 : augmented up to ==> 4140  samples\n",
      "Class  37 : augmented up to ==> 4320  samples\n",
      "Class  37 : augmented up to ==> 4500  samples\n",
      "Class  37 : augmented up to ==> 4680  samples\n",
      "Class  37 : augmented up to ==> 4860  samples\n",
      "Class  37 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  38 | original size =  1860   ....\n",
      "Class  38 : augmented up to ==> 3720  samples\n",
      "Class  38 : augmented up to ==> 5580  samples\n",
      "Augmenting class:  39 | original size =  270   ....\n",
      "Class  39 : augmented up to ==> 540  samples\n",
      "Class  39 : augmented up to ==> 810  samples\n",
      "Class  39 : augmented up to ==> 1080  samples\n",
      "Class  39 : augmented up to ==> 1350  samples\n",
      "Class  39 : augmented up to ==> 1620  samples\n",
      "Class  39 : augmented up to ==> 1890  samples\n",
      "Class  39 : augmented up to ==> 2160  samples\n",
      "Class  39 : augmented up to ==> 2430  samples\n",
      "Class  39 : augmented up to ==> 2700  samples\n",
      "Class  39 : augmented up to ==> 2970  samples\n",
      "Class  39 : augmented up to ==> 3240  samples\n",
      "Class  39 : augmented up to ==> 3510  samples\n",
      "Class  39 : augmented up to ==> 3780  samples\n",
      "Class  39 : augmented up to ==> 4050  samples\n",
      "Class  39 : augmented up to ==> 4320  samples\n",
      "Class  39 : augmented up to ==> 4590  samples\n",
      "Class  39 : augmented up to ==> 4860  samples\n",
      "Class  39 : augmented up to ==> 5130  samples\n",
      "Augmenting class:  40 | original size =  300   ....\n",
      "Class  40 : augmented up to ==> 600  samples\n",
      "Class  40 : augmented up to ==> 900  samples\n",
      "Class  40 : augmented up to ==> 1200  samples\n",
      "Class  40 : augmented up to ==> 1500  samples\n",
      "Class  40 : augmented up to ==> 1800  samples\n",
      "Class  40 : augmented up to ==> 2100  samples\n",
      "Class  40 : augmented up to ==> 2400  samples\n",
      "Class  40 : augmented up to ==> 2700  samples\n",
      "Class  40 : augmented up to ==> 3000  samples\n",
      "Class  40 : augmented up to ==> 3300  samples\n",
      "Class  40 : augmented up to ==> 3600  samples\n",
      "Class  40 : augmented up to ==> 3900  samples\n",
      "Class  40 : augmented up to ==> 4200  samples\n",
      "Class  40 : augmented up to ==> 4500  samples\n",
      "Class  40 : augmented up to ==> 4800  samples\n",
      "Class  40 : augmented up to ==> 5100  samples\n",
      "Augmenting class:  41 | original size =  210   ....\n",
      "Class  41 : augmented up to ==> 420  samples\n",
      "Class  41 : augmented up to ==> 630  samples\n",
      "Class  41 : augmented up to ==> 840  samples\n",
      "Class  41 : augmented up to ==> 1050  samples\n",
      "Class  41 : augmented up to ==> 1260  samples\n",
      "Class  41 : augmented up to ==> 1470  samples\n",
      "Class  41 : augmented up to ==> 1680  samples\n",
      "Class  41 : augmented up to ==> 1890  samples\n",
      "Class  41 : augmented up to ==> 2100  samples\n",
      "Class  41 : augmented up to ==> 2310  samples\n",
      "Class  41 : augmented up to ==> 2520  samples\n",
      "Class  41 : augmented up to ==> 2730  samples\n",
      "Class  41 : augmented up to ==> 2940  samples\n",
      "Class  41 : augmented up to ==> 3150  samples\n",
      "Class  41 : augmented up to ==> 3360  samples\n",
      "Class  41 : augmented up to ==> 3570  samples\n",
      "Class  41 : augmented up to ==> 3780  samples\n",
      "Class  41 : augmented up to ==> 3990  samples\n",
      "Class  41 : augmented up to ==> 4200  samples\n",
      "Class  41 : augmented up to ==> 4410  samples\n",
      "Class  41 : augmented up to ==> 4620  samples\n",
      "Class  41 : augmented up to ==> 4830  samples\n",
      "Class  41 : augmented up to ==> 5040  samples\n",
      "Augmenting class:  42 | original size =  210   ....\n",
      "Class  42 : augmented up to ==> 420  samples\n",
      "Class  42 : augmented up to ==> 630  samples\n",
      "Class  42 : augmented up to ==> 840  samples\n",
      "Class  42 : augmented up to ==> 1050  samples\n",
      "Class  42 : augmented up to ==> 1260  samples\n",
      "Class  42 : augmented up to ==> 1470  samples\n",
      "Class  42 : augmented up to ==> 1680  samples\n",
      "Class  42 : augmented up to ==> 1890  samples\n",
      "Class  42 : augmented up to ==> 2100  samples\n",
      "Class  42 : augmented up to ==> 2310  samples\n",
      "Class  42 : augmented up to ==> 2520  samples\n",
      "Class  42 : augmented up to ==> 2730  samples\n",
      "Class  42 : augmented up to ==> 2940  samples\n",
      "Class  42 : augmented up to ==> 3150  samples\n",
      "Class  42 : augmented up to ==> 3360  samples\n",
      "Class  42 : augmented up to ==> 3570  samples\n",
      "Class  42 : augmented up to ==> 3780  samples\n",
      "Class  42 : augmented up to ==> 3990  samples\n",
      "Class  42 : augmented up to ==> 4200  samples\n",
      "Class  42 : augmented up to ==> 4410  samples\n",
      "Class  42 : augmented up to ==> 4620  samples\n",
      "Class  42 : augmented up to ==> 4830  samples\n",
      "Class  42 : augmented up to ==> 5040  samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "min_samples_per_class = 5000\n",
    "X_train_aug =np.empty((0, 32, 32, 3))\n",
    "y_train_aug =np.empty(0, dtype='uint8')\n",
    "\n",
    "for c in range(n_classes):\n",
    "        \n",
    "    #filtering out X and y belonging to class c\n",
    "    class_c_X = X_train_preprocessed[y_train==c]\n",
    "    class_c_y = y_train[y_train==c]\n",
    "    \n",
    "    X_train_aug = np.append(X_train_aug, class_c_X, axis=0)\n",
    "    y_train_aug = np.append(y_train_aug, class_c_y, axis=0)\n",
    "    \n",
    "    ori_class_c_size = len(class_c_y)\n",
    "    class_c_size = ori_class_c_size\n",
    "    print('Augmenting class: ', c, '| original size = ', class_c_size, '  ....')\n",
    "    #iterating across all samples in class c (one batch) and augmenting them as specified \n",
    "    #in the datagen object above\n",
    "    for X, y in datagen.flow(class_c_X, class_c_y, batch_size=ori_class_c_size, seed=1000001+c*53):\n",
    "        X_train_aug = np.append(X_train_aug, X, axis=0)\n",
    "        y_train_aug = np.append(y_train_aug, y, axis=0)\n",
    "        \n",
    "        class_c_size += ori_class_c_size\n",
    "        print('Class ', c, ': augmented up to ==>', class_c_size, ' samples')\n",
    "        \n",
    "        #breaking infinite augmentation loop when the total samples for class c \n",
    "        #passes min_samples_per_class value\n",
    "        if class_c_size >= min_samples_per_class:\n",
    "            break\n",
    "            \n",
    "            \n",
    "\n",
    "#Augmented data output is segregated by class, i.e. it was augmented by class-wise \n",
    "#hence multple augmented copies of a class were appended one after another. \n",
    "#Therefore all samples of a given class is put together. Hence we have to shuffle this to avoid bias effects\n",
    "#on training\n",
    "X_train_aug, y_train_aug = shuffle(X_train_aug, y_train_aug, random_state=1000001)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class distribution of training set after augmentation...\n",
      "sample distribution among classes.....\n",
      "Class  0 :  5040\n",
      "Class  1 :  5940\n",
      "Class  2 :  6030\n",
      "Class  3 :  5040\n",
      "Class  4 :  5310\n",
      "Class  5 :  6600\n",
      "Class  6 :  5040\n",
      "Class  7 :  5160\n",
      "Class  8 :  5040\n",
      "Class  9 :  5280\n",
      "Class  10 :  5400\n",
      "Class  11 :  5850\n",
      "Class  12 :  5670\n",
      "Class  13 :  5760\n",
      "Class  14 :  5520\n",
      "Class  15 :  5400\n",
      "Class  16 :  5040\n",
      "Class  17 :  5940\n",
      "Class  18 :  5400\n",
      "Class  19 :  5040\n",
      "Class  20 :  5100\n",
      "Class  21 :  5130\n",
      "Class  22 :  5280\n",
      "Class  23 :  5400\n",
      "Class  24 :  5040\n",
      "Class  25 :  5400\n",
      "Class  26 :  5400\n",
      "Class  27 :  5040\n",
      "Class  28 :  5280\n",
      "Class  29 :  5040\n",
      "Class  30 :  5070\n",
      "Class  31 :  5520\n",
      "Class  32 :  5040\n",
      "Class  33 :  5391\n",
      "Class  34 :  5040\n",
      "Class  35 :  5400\n",
      "Class  36 :  5280\n",
      "Class  37 :  5040\n",
      "Class  38 :  5580\n",
      "Class  39 :  5130\n",
      "Class  40 :  5100\n",
      "Class  41 :  5040\n",
      "Class  42 :  5040\n"
     ]
    }
   ],
   "source": [
    "print('class distribution of training set after augmentation...')\n",
    "print_hist(X_train_aug, y_train_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving pre-processed and augmented data sets in to a pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed and augmented dataset were successfully saved in a pickle file\n"
     ]
    }
   ],
   "source": [
    "preprocessed_data_file = 'final_data/pre_processed_and_augmented_data'\n",
    "preprocessed_dict = {}\n",
    "\n",
    "preprocessed_dict['X_train_aug'] = X_train_aug\n",
    "preprocessed_dict['y_train_aug'] = y_train_aug\n",
    "preprocessed_dict['X_valid_preproc'] = X_valid_preprocessed\n",
    "preprocessed_dict['y_valid'] = y_valid\n",
    "preprocessed_dict['X_test_preproc'] = X_test_preprocessed\n",
    "preprocessed_dict['y_test'] = y_test\n",
    "\n",
    "try:\n",
    "    with open(preprocessed_data_file, 'wb') as pfile:\n",
    "        pickle.dump(preprocessed_dict, pfile, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "    print('Exception occured in saving to pickle:', e)\n",
    "    raise\n",
    "print('Pre-processed and augmented dataset were successfully saved in a pickle file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset from the saved pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed and augmented dataset were successfully loaded in a dictionary and then to variables of same name\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "saved_data_file = 'final_data/pre_processed_and_augmented_data'\n",
    "\n",
    "try:\n",
    "    with open(saved_data_file, 'rb') as pfile:\n",
    "        saved_dict = pickle.load(pfile)\n",
    "except Exception as e:\n",
    "    print('Exception occured in loading pickle file:', e)\n",
    "    raise\n",
    "print('Pre-processed and augmented dataset were successfully loaded in a dictionary and then to variables of same name')\n",
    "\n",
    "#assigning dictonary values to variables\n",
    "X_train_aug = saved_dict['X_train_aug']\n",
    "y_train_aug = saved_dict['y_train_aug']\n",
    "X_valid_preprocessed = saved_dict['X_valid_preproc']\n",
    "y_valid = saved_dict['y_valid']\n",
    "X_test_preprocessed = saved_dict['X_test_preproc']\n",
    "y_test = saved_dict['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "rate = 0.001\n",
    "dropout_conv = 1.\n",
    "dropout_fc = 1.\n",
    "\n",
    "\n",
    "#parameters for weights and bias initialization\n",
    "mu = 0\n",
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x, w, b, dropout_conv, dropout_fc):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    \n",
    "  #==========================Layer 1 - Convolution===================================\n",
    "    #Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    #conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
    "    #conv1_W = tf.get_variable(shape=[5, 5, 3, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #conv1_b = tf.Variable(tf.zeros(20))\n",
    "    conv1   = tf.nn.conv2d(x, w['wc1'], strides=[1, 1, 1, 1], padding='VALID') + b['bc1']\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    #Dropout\n",
    "    conv1_drop =  tf.nn.dropout(pool1, dropout_conv)\n",
    "    \n",
    "    \n",
    "  #==========================Layer 2 - Convolution===================================\n",
    "    #Layer 2: Convolutional. Output = 10x10x16.\n",
    "    #conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    #conv2_W = tf.get_variable(shape=[5, 5, 6, 36], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #conv2_b = tf.Variable(tf.zeros(36))\n",
    "    conv2   = tf.nn.conv2d(conv1_drop, w['wc2'], strides=[1, 1, 1, 1], padding='VALID') + b['bc2']\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    #Dropout\n",
    "    conv2_drop =  tf.nn.dropout(pool2, dropout_conv)\n",
    "    \n",
    "    \n",
    "  #==========================Layer 3 - Fully Connected===================================\n",
    "    \n",
    "    # SOLUTION: Flatten. Input = 5x5x36. Output = 400.\n",
    "    fc0   = flatten(conv2_drop)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    #fc1_W = tf.Variable(tf.truncated_normal(shape=(900, 120), mean = mu, stddev = sigma))\n",
    "    #fc1_W = tf.get_variable(shape=[900, 400], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #fc1_b = tf.Variable(tf.zeros(400))\n",
    "    fc1   = tf.matmul(fc0, w['wf1']) + b['bf1']\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    \n",
    "    #Dropout\n",
    "    fc1_drop =  tf.nn.dropout(fc1, dropout_fc)\n",
    "    \n",
    "    \n",
    "#==========================Layer 4 - Fully Connected===================================    \n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    #fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    #fc2_W = tf.get_variable(shape=[400, 150], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #fc2_b  = tf.Variable(tf.zeros(150))\n",
    "    fc2    = tf.matmul(fc1_drop, w['wf2']) + b['bf2']\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    \n",
    "    #Dropout\n",
    "    fc2_drop =  tf.nn.dropout(fc2, dropout_fc)\n",
    "    \n",
    "    \n",
    "#==========================Layer 5 - Fully Connected===================================    \n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    #fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    #fc3_W = tf.get_variable(shape=[150, 43], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    #fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2_drop, w['wf3']) + b['bf3']\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weights and biases\n",
    "\n",
    "weights = {\n",
    "     'wc1': tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma)),\n",
    "     'wc2': tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma)),\n",
    "     'wf1': tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma)),\n",
    "     'wf2': tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma)),\n",
    "     'wf3': tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "}\n",
    "\n",
    "biases ={\n",
    "     'bc1': tf.Variable(tf.zeros(6)),\n",
    "     'bc2': tf.Variable(tf.zeros(16)),\n",
    "     'bf1': tf.Variable(tf.zeros(120)), \n",
    "     'bf2': tf.Variable(tf.zeros(84)),\n",
    "     'bf3': tf.Variable(tf.zeros(43))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place holders, entropies and evalution functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob_conv = tf.placeholder(tf.float32)\n",
    "keep_prob_fc = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = LeNet(x, weights, biases, keep_prob_conv, keep_prob_fc)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        end = offset+BATCH_SIZE    \n",
    "        batch_x, batch_y = X_data[offset:end], y_data[offset:end]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob_conv: 1., keep_prob_fc: 1.})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically in a machine learning problem, we do iterations to improve (or find the best solution) using the training and the validation set only. Once we are statisfied with the training and validation accuracy we pick that model and report the model accuracy by running it on the testing set (**only once**).\n",
    "\n",
    "Training and validation accuracies could also be used as an indication of underfitting(bias) and overfitting(varience). A low accuracy on the training and validation sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Training Accuracy = 0.593\n",
      "Validation Accuracy = 0.696\n",
      "\n",
      "EPOCH 2 ...\n",
      "Training Accuracy = 0.797\n",
      "Validation Accuracy = 0.858\n",
      "\n",
      "EPOCH 3 ...\n",
      "Training Accuracy = 0.853\n",
      "Validation Accuracy = 0.905\n",
      "\n",
      "EPOCH 4 ...\n",
      "Training Accuracy = 0.895\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "EPOCH 5 ...\n",
      "Training Accuracy = 0.899\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 6 ...\n",
      "Training Accuracy = 0.935\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 7 ...\n",
      "Training Accuracy = 0.946\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "EPOCH 8 ...\n",
      "Training Accuracy = 0.939\n",
      "Validation Accuracy = 0.952\n",
      "\n",
      "EPOCH 9 ...\n",
      "Training Accuracy = 0.954\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "EPOCH 10 ...\n",
      "Training Accuracy = 0.949\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 11 ...\n",
      "Training Accuracy = 0.954\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 12 ...\n",
      "Training Accuracy = 0.963\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 13 ...\n",
      "Training Accuracy = 0.964\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "EPOCH 14 ...\n",
      "Training Accuracy = 0.972\n",
      "Validation Accuracy = 0.963\n",
      "\n",
      "EPOCH 15 ...\n",
      "Training Accuracy = 0.957\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "EPOCH 16 ...\n",
      "Training Accuracy = 0.966\n",
      "Validation Accuracy = 0.949\n",
      "\n",
      "EPOCH 17 ...\n",
      "Training Accuracy = 0.974\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "EPOCH 18 ...\n",
      "Training Accuracy = 0.965\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 19 ...\n",
      "Training Accuracy = 0.969\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 20 ...\n",
      "Training Accuracy = 0.971\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "EPOCH 21 ...\n",
      "Training Accuracy = 0.967\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 22 ...\n",
      "Training Accuracy = 0.969\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "EPOCH 23 ...\n",
      "Training Accuracy = 0.965\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "EPOCH 24 ...\n",
      "Training Accuracy = 0.971\n",
      "Validation Accuracy = 0.966\n",
      "\n",
      "EPOCH 25 ...\n",
      "Training Accuracy = 0.966\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 26 ...\n",
      "Training Accuracy = 0.977\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "EPOCH 27 ...\n",
      "Training Accuracy = 0.974\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 28 ...\n",
      "Training Accuracy = 0.969\n",
      "Validation Accuracy = 0.952\n",
      "\n",
      "EPOCH 29 ...\n",
      "Training Accuracy = 0.970\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "EPOCH 30 ...\n",
      "Training Accuracy = 0.975\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 31 ...\n",
      "Training Accuracy = 0.975\n",
      "Validation Accuracy = 0.965\n",
      "\n",
      "EPOCH 32 ...\n",
      "Training Accuracy = 0.968\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "EPOCH 33 ...\n",
      "Training Accuracy = 0.977\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "EPOCH 34 ...\n",
      "Training Accuracy = 0.972\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "EPOCH 35 ...\n",
      "Training Accuracy = 0.974\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "EPOCH 36 ...\n",
      "Training Accuracy = 0.978\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "EPOCH 37 ...\n",
      "Training Accuracy = 0.964\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 38 ...\n",
      "Training Accuracy = 0.978\n",
      "Validation Accuracy = 0.968\n",
      "\n",
      "EPOCH 39 ...\n",
      "Training Accuracy = 0.977\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "EPOCH 40 ...\n",
      "Training Accuracy = 0.975\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "EPOCH 41 ...\n",
      "Training Accuracy = 0.980\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "EPOCH 42 ...\n",
      "Training Accuracy = 0.980\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "EPOCH 43 ...\n",
      "Training Accuracy = 0.974\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "EPOCH 44 ...\n",
      "Training Accuracy = 0.974\n",
      "Validation Accuracy = 0.965\n",
      "\n",
      "EPOCH 45 ...\n",
      "Training Accuracy = 0.977\n",
      "Validation Accuracy = 0.965\n",
      "\n",
      "EPOCH 46 ...\n",
      "Training Accuracy = 0.969\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "EPOCH 47 ...\n",
      "Training Accuracy = 0.981\n",
      "Validation Accuracy = 0.963\n",
      "\n",
      "EPOCH 48 ...\n",
      "Training Accuracy = 0.974\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "EPOCH 49 ...\n",
      "Training Accuracy = 0.982\n",
      "Validation Accuracy = 0.965\n",
      "\n",
      "EPOCH 50 ...\n",
      "Training Accuracy = 0.979\n",
      "Validation Accuracy = 0.967\n",
      "\n",
      "Model saved\n",
      "Test Accuracy = 0.947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dataset_size = len(X_train_aug)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        X_train, y_train = shuffle(X_train_aug, y_train_aug)\n",
    "        batch_no = 0\n",
    "        for offset in range(0, dataset_size, BATCH_SIZE):\n",
    "\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob_conv: dropout_conv, \n",
    "                                                    keep_prob_fc: dropout_fc})\n",
    "                        \n",
    "        train_accuracy = evaluate(X_train_aug, y_train_aug)\n",
    "        validation_accuracy = evaluate(X_valid_preprocessed, y_valid)\n",
    "        \n",
    "        print(\"Training Accuracy = {:.3f}\".format(train_accuracy))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "     \n",
    "    #Saving the trained model in to a file using tf.Saver\n",
    "    saver = tf.train.Saver()    \n",
    "    saver.save(sess, './final_model/lenet')\n",
    "    print(\"Model saved\")\n",
    "    \n",
    "    #Printing test accuracy using the model in the session\n",
    "    test_accuracy = evaluate(X_test_preprocessed, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
